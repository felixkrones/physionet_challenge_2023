{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import os\n",
    "from helper_code import *\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from scipy.stats import ttest_ind\n",
    "import seaborn as sns\n",
    "import statsmodels\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "\n",
    "from team_code import get_features, get_outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"/Users/felixkrones/python_projects/data/physionet_challenge_2023/files/i-care/1.0/test\"\n",
    "output_dir = \"/Users/felixkrones/python_projects/data/physionet_challenge_2023/preprocessed_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if output directory exists\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Get and prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_ids = find_data_folders(data_folder)\n",
    "num_patients = len(patient_ids)\n",
    "\n",
    "if num_patients==0:\n",
    "    raise FileNotFoundError('No data was provided.')\n",
    "\n",
    "features = list()\n",
    "recordings = list()\n",
    "outcomes = list()\n",
    "cpcs = list()\n",
    "for i in tqdm(range(num_patients)):\n",
    "    # Load data.\n",
    "    patient_id = patient_ids[i]\n",
    "    patient_metadata = load_challenge_data(data_folder, patient_id)\n",
    "    recording_ids = find_recording_files(data_folder, patient_id)\n",
    "    recording_metadata_file = os.path.join(data_folder, patient_id, patient_id + '.tsv')\n",
    "    recording_metadata = load_text_file(recording_metadata_file)\n",
    "    hours = get_variable(recording_metadata, 'Hour', str)\n",
    "    times = get_variable(recording_metadata, 'Time', str)\n",
    "    qualities = get_variable(recording_metadata, 'Quality', str)\n",
    "    recordings_data_eeg = list()\n",
    "    recordings_data_ecg = list()\n",
    "    for recording_id in recording_ids:\n",
    "        if not is_nan(recording_id):\n",
    "            recording_location_eeg = os.path.join(data_folder, patient_id, '{}_{}'.format(recording_id, \"eeg\"))\n",
    "            recording_location_ecg = os.path.join(data_folder, patient_id, '{}_{}'.format(recording_id, \"ecg\"))\n",
    "            recording_data_eeg, channels_eeg, sampling_frequency_eeg = load_recording_data(recording_location_eeg)\n",
    "            recording_data_ecg, channels_ecg, sampling_frequency_ecg = load_recording_data(recording_location_ecg)\n",
    "        else:\n",
    "            recording_data_eeg = None\n",
    "            sampling_frequency_eeg = None\n",
    "            channels_eeg = None\n",
    "            recording_data_ecg = None\n",
    "            sampling_frequency_ecg = None\n",
    "            channels_ecg = None\n",
    "        recordings_data_eeg.append((recording_data_eeg, sampling_frequency_eeg, channels_eeg))\n",
    "        recordings_data_ecg.append((recording_data_ecg, sampling_frequency_ecg, channels_ecg))\n",
    "\n",
    "    # Get recording dataframe\n",
    "    df_recordings = pd.DataFrame(recordings_data_eeg, columns=[\"signals_eeg\", \"frequencies_eeg\", \"channels_eeg\"])\n",
    "    df_recordings[\"signals_ecg\"] = [x[0] for x in recordings_data_ecg]\n",
    "    df_recordings[\"frequencies_ecg\"] = [x[1] for x in recordings_data_ecg]\n",
    "    df_recordings[\"channels_ecg\"] = [x[2] for x in recordings_data_ecg]\n",
    "    df_recordings[\"quality_score\"] = qualities\n",
    "    df_recordings[\"hours\"] = hours\n",
    "    df_recordings[\"times\"] = times\n",
    "    df_recordings[\"patient_id\"] = patient_id\n",
    "    recordings.append(df_recordings)\n",
    "\n",
    "    # Extract features.\n",
    "    current_features = get_features(data_folder, patient_id, return_as_dict=True)\n",
    "    features.append(current_features)\n",
    "\n",
    "    # Extract labels.\n",
    "    current_outcome = get_outcome(patient_metadata)\n",
    "    outcomes.append(current_outcome)\n",
    "    current_cpc = get_cpc(patient_metadata)\n",
    "    cpcs.append(current_cpc)\n",
    "\n",
    "df_meta = pd.DataFrame(features)\n",
    "df_meta[\"patient_id\"] = patient_ids\n",
    "df_meta[\"outcomes\"] = np.vstack(outcomes)\n",
    "df_meta[\"cpcs\"]  = np.vstack(cpcs)\n",
    "df_recordings = pd.concat(recordings, ignore_index=True)\n",
    "df_recordings_not_nan = df_recordings[df_recordings[\"signals\"].notna()]\n",
    "df_combined = df_recordings_not_nan.merge(df_meta, on=\"patient_id\", how=\"left\")\n",
    "assert df_combined.shape[0] == df_recordings_not_nan.shape[0], \"The number of rows in the combined dataframe should be the same as the number of rows in the recordings dataframe.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create outcome labels, where 1 is poor and 0 is good.\n",
    "df_meta[\"outcome_labels\"] = df_meta[\"outcomes\"].apply(lambda x: \"poor\" if x == 1 else \"good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data.\n",
    "df_meta.to_csv(output_dir + \"df_meta.csv\", index=False)\n",
    "df_recordings_not_nan.to_pickle(output_dir + \"df_recordings_not_nan.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data.\n",
    "df_meta = pd.read_csv(output_dir + \"df_meta.csv\")\n",
    "df_recordings_not_nan = pd.read_pickle(output_dir + \"df_recordings_not_nan.pkl\")\n",
    "df_combined = df_recordings_not_nan.merge(df_meta, on=\"patient_id\", how=\"left\")\n",
    "assert df_combined.shape[0] == df_recordings_not_nan.shape[0], \"The number of rows in the combined dataframe should be the same as the number of rows in the recordings dataframe.\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Metadata analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recordings\n",
    "print(\"Number of patients: {}\".format(df_meta.shape[0]))\n",
    "print(\"Number of recordings: {}\".format(df_recordings_not_nan.shape[0]))\n",
    "print(\"Number of signals: {}\".format(df_recordings_not_nan[\"signals\"].apply(lambda x: x.shape[0]).sum()))\n",
    "print(\"{}\".format(df_recordings_not_nan.shape[0])+\" * 18 = {}\".format(df_recordings_not_nan.shape[0]*18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stats\n",
    "df_meta[[\"age\", \"female\", \"male\", \"other\", \"rosc\", \"ttm\", \"outcomes\", \"cpcs\"]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of ROSC information\n",
    "df_meta[['rosc', 'patient_id']].head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender outcomes\n",
    "pd.crosstab(df_meta[\"male\"], df_meta[\"outcomes\"], margins=True, normalize=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender vs outcome\n",
    "pd.crosstab(df_meta[\"male\"], df_meta[\"outcomes\"], margins=True, normalize=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot ROSC vs CPCS including outcome as color and legend labelling 1 as poor and 0 as good. Include option to set overall font size\n",
    "plt.figure(figsize=(8, 5.5))\n",
    "sns.scatterplot(data=df_meta, x=\"rosc\", y=\"cpcs\", hue=\"outcome_labels\", palette=\"Set2\", s=100)\n",
    "plt.xlabel(\"ROSC\")\n",
    "plt.ylabel(\"CPCS\")\n",
    "plt.legend(title=\"Outcome\", loc=\"center right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency histogram ROSC including outcome_labels as color with alpha. Include option to set overall font size\n",
    "plt.figure(figsize=(8, 5.5))\n",
    "sns.histplot(data=df_meta, x=\"rosc\", hue=\"outcome_labels\", palette=\"Set2\", alpha=0.5, stat=\"probability\", bins=20)\n",
    "plt.xlabel('ROSC')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# T test with num_recordings and outcome_labels\n",
    "df_aux_good = df_meta[df_meta[\"outcome_labels\"] == \"good\"]\n",
    "df_aux_poor = df_meta[df_meta[\"outcome_labels\"] == \"poor\"]\n",
    "print(ttest_ind(df_aux_good[\"rosc\"], df_aux_poor[\"rosc\"], nan_policy=\"omit\"))\n",
    "print(np.mean(df_aux_good[\"rosc\"]))\n",
    "print(np.mean(df_aux_poor[\"rosc\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPC vs TTM\n",
    "df_meta[\"ttm_str\"] = df_meta[\"ttm\"].apply(lambda x: \"33\" if x == 33.0 else \"36\" if x == 36.0 else \"nan\")\n",
    "print(pd.crosstab(df_meta[\"outcomes\"], df_meta[\"ttm_str\"], margins=True, normalize=\"columns\"))\n",
    "\n",
    "# T test with num_recordings and outcome_labels\n",
    "df_aux_33 = df_meta[df_meta[\"ttm_str\"] == \"33\"]\n",
    "df_aux_36 = df_meta[df_meta[\"ttm_str\"] == \"36\"]\n",
    "df_aux_not_nan = df_meta[df_meta[\"ttm_str\"] != \"nan\"]\n",
    "df_aux_nan = df_meta[df_meta[\"ttm_str\"] == \"nan\"]\n",
    "print(\"33 vs 36 average outcome\")\n",
    "print(ttest_ind(df_aux_33[\"outcomes\"], df_aux_36[\"outcomes\"]))\n",
    "print(\"nan vs not_nan average outcome\")\n",
    "print(ttest_ind(df_aux_nan[\"outcomes\"], df_aux_not_nan[\"outcomes\"]))\n",
    "print(\"33 average outcome\")\n",
    "print(np.mean(df_aux_33[\"outcomes\"]))\n",
    "print(\"36 average outcome\")\n",
    "print(np.mean(df_aux_36[\"outcomes\"]))\n",
    "print(\"nan average outcome\")\n",
    "print(np.mean(df_aux_nan[\"outcomes\"]))\n",
    "\n",
    "print(df_meta[\"ttm_str\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPCs vs outcomes\n",
    "pd.crosstab(df_meta[\"cpcs\"], df_meta[\"outcomes\"], margins=True, normalize=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROSC vs age\n",
    "sns.scatterplot(data=df_meta, x=\"age\", y=\"rosc\", hue=\"outcomes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency histogram Age including outcome_labels as color with alpha. Include option to set overall font size\n",
    "plt.figure(figsize=(8, 5.5))\n",
    "sns.histplot(data=df_meta, x=\"age\", hue=\"outcome_labels\", palette=\"Set2\", alpha=0.5, stat=\"probability\", bins=[10,20,30,40,50,60,70,80,90,100])\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# T test with num_recordings and outcome_labels\n",
    "df_aux_good = df_meta[df_meta[\"outcome_labels\"] == \"good\"]\n",
    "df_aux_poor = df_meta[df_meta[\"outcome_labels\"] == \"poor\"]\n",
    "print(ttest_ind(df_aux_good[\"age\"], df_aux_poor[\"age\"], nan_policy=\"omit\"))\n",
    "print(np.mean(df_aux_good[\"age\"]))\n",
    "print(np.mean(df_aux_poor[\"age\"]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. EEG"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quality score\n",
    "sns.histplot(data=df_recordings_not_nan, x=\"quality_score\", bins=10, stat=\"frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max hours distribution\n",
    "sns.histplot(df_combined.groupby(['patient_id'])['hours', 'outcomes'].max(), x=\"hours\", hue=\"outcomes\", bins=10, stat=\"frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of recordings per patient\n",
    "df_aux = df_combined.groupby(['patient_id'])['hours'].count()\n",
    "df_aux = df_aux.reset_index()\n",
    "df_aux.columns = ['patient_id', 'num_recordings']\n",
    "df_aux = df_aux.merge(df_meta[['patient_id', 'outcome_labels', 'cpcs', 'outcomes']], on=\"patient_id\", how=\"left\")\n",
    "\n",
    "# Frequency histogram num_recordings including outcome_labels as color with alpha. Include option to set overall font size\n",
    "plt.figure(figsize=(8, 5.5))\n",
    "sns.histplot(data=df_aux, x=\"num_recordings\", hue=\"outcome_labels\", palette=\"Set2\", alpha=0.5, stat=\"probability\", bins=20)\n",
    "plt.xlabel('num_recordings')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# T test with num_recordings and outcome_labels\n",
    "df_aux_good = df_aux[df_aux[\"outcome_labels\"] == \"good\"]\n",
    "df_aux_poor = df_aux[df_aux[\"outcome_labels\"] == \"poor\"]\n",
    "print(ttest_ind(df_aux_good[\"num_recordings\"], df_aux_poor[\"num_recordings\"]))\n",
    "print(np.mean(df_aux_good[\"num_recordings\"]))\n",
    "print(np.mean(df_aux_poor[\"num_recordings\"]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Plots"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data\n",
    "df_plot_bad_quality = df_recordings_not_nan[df_recordings_not_nan[\"quality_score\"]<0.1].iloc[42]\n",
    "df_plot_good_quality = df_recordings_not_nan[df_recordings_not_nan[\"quality_score\"]>0.99999].iloc[42]\n",
    "good_patient_id = df_meta[df_meta[\"outcomes\"]==0][\"patient_id\"].values[42]\n",
    "bad_patient_id = df_meta[df_meta[\"outcomes\"]==1][\"patient_id\"].values[42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert times column to seconds since zero\n",
    "df_recordings_not_nan[\"100Hz_seconds\"] = df_recordings_not_nan[\"times\"].apply(lambda x: (int(x.split(\":\")[0])*60*60 + int(x.split(\":\")[1])*60)*100)\n",
    "\n",
    "# Get channels\n",
    "channels = df_recordings_not_nan[\"channels\"].values[0]\n",
    "\n",
    "# Filter\n",
    "df_plot_good = df_recordings_not_nan[df_recordings_not_nan.patient_id==good_patient_id]\n",
    "df_plot_bad = df_recordings_not_nan[df_recordings_not_nan.patient_id==bad_patient_id]\n",
    "df_plot_good_last_hour = df_plot_good.iloc[-1]\n",
    "df_plot_bad_last_hour = df_plot_bad.iloc[-1]\n",
    "\n",
    "# Prep\n",
    "empty_signals_good = np.empty((18, 72*60*60*100))\n",
    "empty_signals_bad = np.empty((18, 72*60*60*100))\n",
    "for idx, c in enumerate(channels):\n",
    "    for i, row in df_plot_good.iterrows():\n",
    "        empty_signals_good[idx, row[\"100Hz_seconds\"]:row[\"100Hz_seconds\"]+row[\"signals\"].shape[1]] = row[\"signals\"][idx]\n",
    "    for i, row in df_plot_bad.iterrows():\n",
    "        empty_signals_bad[idx, row[\"100Hz_seconds\"]:row[\"100Hz_seconds\"]+row[\"signals\"].shape[1]] = row[\"signals\"][idx]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Over all hours\n",
    "figure(figsize=(12, 8))\n",
    "plt.plot(empty_signals_good[0, :], label=channels[0])\n",
    "plt.title(f\"Good outcome, patient {good_patient_id}\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last hour in one plot, good outcome\n",
    "figure(figsize=(12, 8))\n",
    "for idx, c in enumerate(df_plot_good_last_hour[\"channels\"]):\n",
    "    plt.plot(df_plot_good_last_hour[\"signals\"][idx], label=c)\n",
    "plt.title(f\"Good outcome, patient {df_plot_good_last_hour['patient_id']} in hour {df_plot_good_last_hour['hours']}, quality {df_plot_good_last_hour['quality_score']}\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last hour in one plot, poor outcome\n",
    "figure(figsize=(12, 8))\n",
    "for idx, c in enumerate(df_plot_bad_last_hour[\"channels\"]):\n",
    "    plt.plot(df_plot_bad_last_hour[\"signals\"][idx], label=c)\n",
    "plt.title(f\"Poor outcome, patient {df_plot_bad_last_hour['patient_id']} in hour {df_plot_bad_last_hour['hours']}, quality {df_plot_bad_last_hour['quality_score']}\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last hour in multiple plots, good outcome\n",
    "fig, axs = plt.subplots(len(df_plot_good_last_hour[\"channels\"]), 1, figsize=(15, 100))\n",
    "for idx, c in enumerate(df_plot_good_last_hour[\"channels\"][:18]):\n",
    "    axs[idx].plot(df_plot_good_last_hour[\"signals\"][idx], label=c)\n",
    "    axs[idx].title.set_text(c)\n",
    "fig.suptitle(f\"Good outcome, patient {df_plot_good_last_hour['patient_id']} in hour {df_plot_good_last_hour['hours']}, quality {df_plot_good_last_hour['quality_score']}\")\n",
    "fig.tight_layout(pad=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectrograms\n",
    "signal_data = df_plot_good_last_hour[\"signals\"]\n",
    "signal_data_lib = librosa.feature.melspectrogram(y=signal_data, sr=100, n_mels=224)\n",
    "#signal_data_lib_num = torch.from_numpy(signal_data_lib)\n",
    "#signal_data_lib_num = nn.functional.normalize(signal_data_lib_num)\n",
    "\n",
    "fig, ax = plt.subplots( figsize=(15, 7))\n",
    "S_dB = librosa.power_to_db(signal_data_lib[0], ref=np.max)\n",
    "img = librosa.display.specshow(S_dB, x_axis='time', sr=100, ax=ax)\n",
    "ax.set(title=f'Mel-frequency spectrogram for {df_plot_good_last_hour[\"patient_id\"]}, channel {df_plot_good_last_hour[\"channels\"][0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last hour in multiple plots, poor outcome\n",
    "fig, axs = plt.subplots(len(df_plot_bad_last_hour[\"channels\"]), 1, figsize=(15, 70))\n",
    "for idx, c in enumerate(df_plot_bad_last_hour[\"channels\"][:18]):\n",
    "    axs[idx].plot(df_plot_bad_last_hour[\"signals\"][idx], label=c)\n",
    "    axs[idx].title.set_text(c)\n",
    "fig.suptitle(f\"Bad outcome, patient {df_plot_bad_last_hour['patient_id']} in hour {df_plot_bad_last_hour['hours']}, quality {df_plot_bad_last_hour['quality_score']}\")\n",
    "fig.tight_layout(pad=7.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good quality\n",
    "figure(figsize=(12, 8))\n",
    "for idx, c in enumerate(df_plot_good_quality[\"channels\"]):\n",
    "    plt.plot(df_plot_good_quality[\"signals\"][idx], label=c)\n",
    "plt.title(f\"Good quality ({df_plot_good_quality['quality_score']}), patient {df_plot_good_quality['patient_id']} in hour {df_plot_good_quality['hours']}\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bad quality\n",
    "figure(figsize=(12, 8))\n",
    "for idx, c in enumerate(df_plot_bad_quality[\"channels\"]):\n",
    "    plt.plot(df_plot_bad_quality[\"signals\"][idx], label=c)\n",
    "plt.title(f\"Bad quality ({df_plot_bad_quality['quality_score']}), patient {df_plot_bad_quality['patient_id']} in hour {df_plot_bad_quality['hours']}\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "physionet_challenge_2023-6KmQCTHE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c7859a263fb6dd3b41dfb416a1f5868f09c8c7d0642e7c4106425a6e93418a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
